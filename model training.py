# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ERXuwWOS9joSdYqZ8fY5_kWI--1jdH3r
"""

from google.colab import drive
drive.mount('/content/drive')
dataset_path = '/content/drive/MyDrive/leukemia.v1i.coco'

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

train_dir = os.path.join(dataset_path, 'train')
test_dir = os.path.join(dataset_path, 'test')
valid_dir = os.path.join(dataset_path, 'valid')

# ImageDataGenerators for loading and preprocessing the images
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Rescale pixel values to [0, 1]
    rotation_range=30,  # Random rotations
    width_shift_range=0.2,  # Random horizontal shifts
    height_shift_range=0.2,  # Random vertical shifts
    shear_range=0.2,  # Random shearing transformations
    zoom_range=0.2,  # Random zoom
    horizontal_flip=True,  # Random horizontal flips
    fill_mode='nearest'  # Fill any new pixels after transformation
)

test_datagen = ImageDataGenerator(rescale=1./255)  # Rescaling for test and validation

# Load datasets using the generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),  # Resize images to 224x224 pixels
    batch_size=32,
    class_mode='categorical',  # Since there are multiple classes
    shuffle=True  # Shuffle the training data
)

valid_generator = test_datagen.flow_from_directory(
    valid_dir,
    target_size=(224, 224),  # Resize images to 224x224 pixels
    batch_size=32,
    class_mode='categorical',  # Since there are multiple classes
    shuffle=False  # Do not shuffle validation data
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),  # Resize images to 224x224 pixels
    batch_size=32,
    class_mode='categorical',  # Since there are multiple classes
    shuffle=False  # Do not shuffle test data
)

# Print the class labels
print("Class labels for training data:", train_generator.class_indices)

from tensorflow.keras.applications import MobileNet

# Build the MobileNet model
base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
base_model.trainable = False

# Add custom layers on top of the base MobileNet model
x = base_model.output
x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce dimensions
x = Dense(1024, activation='relu')(x)  # Fully connected layer
predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # Output layer with softmax

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Print model summary
model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Set Up Callbacks for Efficient Training
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,
    verbose=1,
    restore_best_weights=True
)

checkpoint = ModelCheckpoint(
    'best_mobilenet_model.keras',
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

# Train the Model
history = model.fit(
    train_generator,
    epochs=10,
    validation_data=valid_generator,
    callbacks=[early_stopping, checkpoint],
    batch_size=64
)

# Evaluate the Model
test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

from google.colab import files
model.save("mobilenet_model.keras")
files.download("mobilenet_model.keras")

from tensorflow.keras.models import load_model
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the trained models
mobilenet_v2_model = load_model('/content/drive/MyDrive/mobilenetv2_finetuned.keras')
mobilenet_model = load_model('/content/drive/MyDrive/mobilenet_model.keras')

print("Models Loaded Successfully!")

import tensorflow as tf
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input, Lambda

# Load the two trained models
mobilenet_v2_model = load_model('/content/drive/MyDrive/mobilenetv2_finetuned.keras')
mobilenet_model = load_model('/content/drive/MyDrive/mobilenet_model.keras')

# Freeze the models (no training needed)
mobilenet_v2_model.trainable = False
mobilenet_model.trainable = False

# Define input layer
input_layer = Input(shape=(224, 224, 3))

# Get predictions from both models
pred_1 = mobilenet_v2_model(input_layer)
pred_2 = mobilenet_model(input_layer)

# Soft Voting (Average the Probabilities)
ensemble_output = Lambda(lambda x: (x[0] + x[1]) / 2)([pred_1, pred_2])

# Create a new model that applies ensemble voting internally
ensemble_model = Model(inputs=input_layer, outputs=ensemble_output)

# Save this new wrapped model
ensemble_model.save("/content/drive/MyDrive/ensemble_model.keras")
print("Ensemble model saved successfully!")

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the saved ensemble model
ensemble_model = tf.keras.models.load_model("/content/drive/MyDrive/mobilenet_model.keras", safe_mode=False)

# Define class labels
class_labels = {0: "Benign", 1: "Malignant-Early", 2: "Malignant-Pre", 3: "Malignant-Pro"}  # Adjust as per your class names

# Function to preprocess the image
def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))  # Resize image to model input size
    img_array = image.img_to_array(img) / 255.0  # Normalize
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array

# Test with an image
test_image_path = "/content/drive/MyDrive/bone-marrow-study-smear-picture-260nw-2493629019.webp"  # Change to an actual test image path
img_array = preprocess_image(test_image_path)

# Make prediction
prediction = ensemble_model.predict(img_array)
predicted_class = np.argmax(prediction, axis=1)[0]  # Get the class index
predicted_label = class_labels[predicted_class]  # Get the label name

# Print the prediction
print(f"Predicted Class: {predicted_class}")
print(f"Predicted Label: {predicted_label}")

import matplotlib.pyplot as plt

# Load and display the image
img = image.load_img(test_image_path, target_size=(224, 224))
plt.imshow(img)
plt.axis("off")
plt.title(f"Predicted: {class_labels[predicted_class]}")
plt.show()

!pip install tensorflow_model_optimization

import os

model_path = "/content/drive/MyDrive/mobilenet_model.keras"
size = os.path.getsize(model_path) / (1024 * 1024)  # Convert bytes to MB
print(f"Model size: {size:.2f} MB")

import tensorflow as tf
import tensorflow_model_optimization as tfmot
from tensorflow.keras import Model, layers
import numpy as np

# Load the trained MobileNet model (Teacher)
teacher_model_path = "/content/drive/MyDrive/mobilenet_model.keras"
teacher_model = tf.keras.models.load_model(teacher_model_path)
teacher_model.trainable = False  # Freeze the teacher model

# Define Knowledge Distillation Loss
def distillation_loss(y_true, y_pred, temperature=2.0, alpha=0.5):
    soft_targets = tf.nn.softmax(y_true / temperature)  # y_true is now soft labels
    soft_outputs = tf.nn.softmax(y_pred / temperature)

    kl_div = tf.keras.losses.KLDivergence()(soft_targets, soft_outputs)
    return alpha * kl_div  # Only distillation loss, no hard label loss


# Define Student Model (Smaller MobileNet)
def create_student_model():
    base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), weights=None, include_top=False)
    x = base_model.output
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(4, activation='softmax')(x)  # 4 classes
    return Model(inputs=base_model.input, outputs=x)

student_model = create_student_model()

# Generate Teacher Predictions as Soft Labels
train_images, train_labels = next(iter(train_generator))  # Get batch
teacher_preds = teacher_model.predict(train_images)  # Get soft labels

def custom_data_generator(generator, teacher_model):
    for images, hard_labels in generator:
        soft_labels = teacher_model.predict(images)  # Get soft labels from teacher
        yield images, soft_labels  # Only return soft labels

train_data = custom_data_generator(train_generator, teacher_model)
valid_data = custom_data_generator(valid_generator, teacher_model)

student_model.compile(optimizer='adam', loss=distillation_loss, metrics=['accuracy'])
student_model.fit(train_data, validation_data=valid_data, epochs=5)

# Apply Pruning to the Student Model
pruning_params = {
    "pruning_schedule": tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.2, final_sparsity=0.8, begin_step=0, end_step=2000)
}
pruned_model = tfmot.sparsity.keras.prune_low_magnitude(student_model, **pruning_params)

# Compile the Pruned Model with Distillation Loss
pruned_model.compile(optimizer='adam', loss=distillation_loss, metrics=['accuracy'])

# Train the Pruned Model
pruned_model.fit(train_data, validation_data=valid_data, epochs=10)  # Additional fine-tuning

# Save the Final Pruned Model
pruned_model_path = "/content/drive/MyDrive/pruned_mobilenet_kd.keras"
pruned_model.save(pruned_model_path)

print(f"Pruned Knowledge Distillation model saved at: {pruned_model_path}")

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the pruned MobileNet model
pruned_model_path = "/content/drive/MyDrive/pruned_mobilenet_kd.keras"
pruned_model = tf.keras.models.load_model(pruned_model_path, custom_objects={"distillation_loss": distillation_loss})

# Load a test image
img_path = "/content/drive/MyDrive/cml-under-microscope-5b85803346e0fb005093fb84.jpg"

# Preprocess the image
img = image.load_img(img_path, target_size=(224, 224))  # Resize to model's input size
img_array = image.img_to_array(img)  # Convert to numpy array
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array = img_array / 255.0  # Normalize to [0,1] range

# Make a prediction
predictions = pruned_model.predict(img_array)

# Get top predicted class
predicted_class = np.argmax(predictions, axis=-1)
print(f"Predicted class: {predicted_class}")

import os

model_path = "/content/drive/MyDrive/pruned_mobilenet_kd.keras"
size = os.path.getsize(model_path) / (1024 * 1024)  # Convert bytes to MB
print(f"Model size: {size:.2f} MB")

import tensorflow as tf

# Re-define the custom loss function
def distillation_loss(y_true, y_pred, temperature=3.0):
    y_true = tf.nn.softmax(y_true / temperature)
    y_pred = tf.nn.softmax(y_pred / temperature)
    return tf.keras.losses.KLDivergence()(y_true, y_pred)

# Register it so Keras can find it
custom_objects = {"distillation_loss": distillation_loss}

# Load the trained pruned model
pruned_model_path = "/content/drive/MyDrive/pruned_mobilenet_kd.keras"
pruned_model = tf.keras.models.load_model(pruned_model_path, custom_objects=custom_objects)

# Convert the model to TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)
tflite_model = converter.convert()

# Save the TFLite model
tflite_model_path = "/content/drive/MyDrive/pruned_mobilenet_kd.tflite"
with open(tflite_model_path, "wb") as f:
    f.write(tflite_model)

print(f"Model converted to TFLite format: {tflite_model_path}")

import os

model_path = "/content/drive/MyDrive/pruned_mobilenet_kd.tflite"
size = os.path.getsize(model_path) / (1024 * 1024)  # Convert bytes to MB
print(f"Model size: {size:.2f} MB")